- How did you design your benchmarks?
We basically utilized a file with length 877130 (number of bytes) and just read
the first byte of every page. With demand paging, a page fault would occur after 
every page, causing the program to page fault 200+ times and cause the program to
read from disk many more times than populating the entire space just once, and reading
through memory continuously. 


- What performance differences did you see?
When we were reading every byte, demand paging was more efficient. 
However, when page faulting on every read, populating the mapping in 
advance became faster (running the benchmark in 0.000970291s as opposed to 
0.30447s for demand paging).

- If you have time / interest, lets try to look at what exactly caused these
performance differences above. Our hardware has special performance counters
for measuring certain events such as number of cache misses, cycles per
instruction, etc. We can use these counters ourselves using the perf
commandline tool. `perf list` will print a list of all the counters your
hardware + OS support. Which counters did you find most interesting? What
results did you observe?
We found the branch-misses, bus-cycles, and cache-misses to be interesting
metrics as part of `perf list`. These are all quite unique ways to gauge and
measure common expensive operations that could cause the instruction reading
pipeline to be flushed for branch misses, and more expensive reading operations 
from disk for cache misses.